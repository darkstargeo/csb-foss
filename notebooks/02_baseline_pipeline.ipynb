{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSB-FOSS: Baseline Pipeline Test\n",
    "\n",
    "This notebook tests the baseline (ArcGIS-compatible) pipeline on a small area of Tennessee.\n",
    "\n",
    "## Pipeline Steps\n",
    "1. Combine CDL rasters (8 years)\n",
    "2. Vectorize combined raster\n",
    "3. Filter by crop presence (COUNT0/COUNT45)\n",
    "4. Eliminate small polygons (tiered: 100, 1000, 10000 m²)\n",
    "5. Simplify polygons (60m tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.windows import Window\n",
    "\n",
    "# Add src to path if needed\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from csb_foss.config import CSBConfig, DataPaths, ProcessingParams, OutputPaths\n",
    "from csb_foss.raster.io import get_cdl_paths_for_years, read_multi_year_stack\n",
    "from csb_foss.raster.combine import combine_cdl_rasters, encode_year_sequence, calculate_crop_counts\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "CDL_DIR = Path(r\"S:\\_STAGING\\01_RASTER_CORPUS\\annual_cdl\")\n",
    "OUTPUT_DIR = Path(\"../output/baseline_test\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "START_YEAR = 2017\n",
    "END_YEAR = 2024\n",
    "\n",
    "# Test window (small area for quick testing)\n",
    "# Adjust these based on your CDL extent\n",
    "TEST_WINDOW = Window(col_off=5000, row_off=5000, width=1000, height=1000)\n",
    "\n",
    "print(f\"CDL directory: {CDL_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Years: {START_YEAR}-{END_YEAR}\")\n",
    "print(f\"Test window: {TEST_WINDOW}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find CDL Rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find CDL paths\n",
    "cdl_paths = get_cdl_paths_for_years(CDL_DIR, START_YEAR, END_YEAR)\n",
    "\n",
    "print(f\"Found {len(cdl_paths)} CDL rasters:\")\n",
    "for year, path in sorted(cdl_paths.items()):\n",
    "    print(f\"  {year}: {path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Combine CDL Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read multi-year stack for test window\n",
    "print(\"Loading CDL stack...\")\n",
    "stack, years, metadata = read_multi_year_stack(cdl_paths, window=TEST_WINDOW)\n",
    "\n",
    "print(f\"Stack shape: {stack.shape} (years, height, width)\")\n",
    "print(f\"Years: {years}\")\n",
    "print(f\"Transform: {metadata['transform']}\")\n",
    "print(f\"CRS: {metadata['crs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode year sequence\n",
    "print(\"Encoding year sequences...\")\n",
    "coded, lookup = encode_year_sequence(stack)\n",
    "\n",
    "print(f\"Coded raster shape: {coded.shape}\")\n",
    "print(f\"Unique signatures: {len(lookup)}\")\n",
    "\n",
    "# Calculate counts\n",
    "counts = calculate_crop_counts(lookup, len(years))\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample signatures (code -> values -> count0, count45):\")\n",
    "for i, (code, values) in enumerate(list(lookup.items())[:5]):\n",
    "    c0, c45 = counts[code]\n",
    "    print(f\"  {code}: {values} -> COUNT0={c0}, COUNT45={c45}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i, (year, ax) in enumerate(zip(years, axes.flat)):\n",
    "    im = ax.imshow(stack[i], cmap='terrain', vmin=0, vmax=255)\n",
    "    ax.set_title(f\"CDL {year}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"CDL Time Series\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Combined signature\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(coded, cmap='nipy_spectral')\n",
    "ax.set_title(f\"Combined Signatures ({len(lookup)} unique)\")\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vectorize Combined Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape\n",
    "import json\n",
    "\n",
    "print(\"Vectorizing...\")\n",
    "\n",
    "# Create lookup JSON for enrichment\n",
    "lookup_data = {\n",
    "    str(k): {\n",
    "        \"values\": list(v),\n",
    "        \"years\": years,\n",
    "        \"count0\": counts[k][0],\n",
    "        \"count45\": counts[k][1],\n",
    "    }\n",
    "    for k, v in lookup.items()\n",
    "}\n",
    "\n",
    "# Vectorize\n",
    "geometries = []\n",
    "gridcodes = []\n",
    "\n",
    "for geom, val in shapes(coded.astype('int32'), transform=metadata['transform']):\n",
    "    geometries.append(shape(geom))\n",
    "    gridcodes.append(int(val))\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    {\"gridcode\": gridcodes},\n",
    "    geometry=geometries,\n",
    "    crs=metadata['crs'],\n",
    ")\n",
    "\n",
    "print(f\"Created {len(gdf)} polygons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich with attributes from lookup\n",
    "for i, year in enumerate(years):\n",
    "    col = f\"cdl_{year}\"\n",
    "    gdf[col] = gdf[\"gridcode\"].apply(\n",
    "        lambda x: lookup_data.get(str(x), {}).get(\"values\", [None] * len(years))[i]\n",
    "    )\n",
    "\n",
    "gdf[\"count0\"] = gdf[\"gridcode\"].apply(\n",
    "    lambda x: lookup_data.get(str(x), {}).get(\"count0\", 0)\n",
    ")\n",
    "gdf[\"count45\"] = gdf[\"gridcode\"].apply(\n",
    "    lambda x: lookup_data.get(str(x), {}).get(\"count45\", 0)\n",
    ")\n",
    "gdf[\"shape_area\"] = gdf.geometry.area\n",
    "\n",
    "print(f\"Columns: {list(gdf.columns)}\")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter by Crop Presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csb_foss.vector.vectorize import filter_by_crop_presence\n",
    "\n",
    "print(f\"Before filter: {len(gdf)} polygons\")\n",
    "\n",
    "gdf_filtered = filter_by_crop_presence(\n",
    "    gdf,\n",
    "    min_crop_years=2,\n",
    "    min_area_single_year=10000,\n",
    ")\n",
    "\n",
    "print(f\"After filter: {len(gdf_filtered)} polygons\")\n",
    "print(f\"Removed: {len(gdf) - len(gdf_filtered)} non-cropland polygons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize filtered vs unfiltered\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "gdf.plot(ax=axes[0], column='count0', cmap='YlGn', legend=True)\n",
    "axes[0].set_title(f\"All polygons ({len(gdf)})\")\n",
    "\n",
    "gdf_filtered.plot(ax=axes[1], column='count0', cmap='YlGn', legend=True)\n",
    "axes[1].set_title(f\"Filtered polygons ({len(gdf_filtered)})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Eliminate Small Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csb_foss.vector.eliminate import tiered_eliminate\n",
    "\n",
    "print(f\"Before elimination: {len(gdf_filtered)} polygons\")\n",
    "print(f\"Area range: {gdf_filtered.shape_area.min():.1f} - {gdf_filtered.shape_area.max():.1f} m²\")\n",
    "\n",
    "gdf_eliminated = tiered_eliminate(\n",
    "    gdf_filtered,\n",
    "    thresholds=[100, 1000, 10000, 10000],\n",
    "    progress=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nAfter elimination: {len(gdf_eliminated)} polygons\")\n",
    "print(f\"Area range: {gdf_eliminated.shape_area.min():.1f} - {gdf_eliminated.shape_area.max():.1f} m²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Simplify Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csb_foss.vector.simplify import simplify_polygons\n",
    "\n",
    "print(f\"Before simplification: {len(gdf_eliminated)} polygons\")\n",
    "\n",
    "gdf_simplified = simplify_polygons(\n",
    "    gdf_eliminated,\n",
    "    tolerance=60.0,  # 60 meters (matching ArcGIS)\n",
    "    progress=True,\n",
    ")\n",
    "\n",
    "print(f\"After simplification: {len(gdf_simplified)} polygons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare before/after simplification\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "gdf_eliminated.plot(ax=axes[0], facecolor='lightblue', edgecolor='darkblue', linewidth=0.5)\n",
    "axes[0].set_title(f\"Before simplification ({len(gdf_eliminated)} polygons)\")\n",
    "\n",
    "gdf_simplified.plot(ax=axes[1], facecolor='lightgreen', edgecolor='darkgreen', linewidth=0.5)\n",
    "axes[1].set_title(f\"After simplification ({len(gdf_simplified)} polygons)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final result\n",
    "output_path = OUTPUT_DIR / \"csb_baseline_test.gpkg\"\n",
    "gdf_simplified.to_file(output_path, driver=\"GPKG\")\n",
    "print(f\"Saved to: {output_path}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== BASELINE PIPELINE SUMMARY ===\")\n",
    "print(f\"Input years: {START_YEAR}-{END_YEAR} ({len(years)} years)\")\n",
    "print(f\"Test area: {TEST_WINDOW.width} x {TEST_WINDOW.height} pixels\")\n",
    "print(f\"Unique signatures: {len(lookup)}\")\n",
    "print(f\"Raw polygons: {len(gdf)}\")\n",
    "print(f\"After crop filter: {len(gdf_filtered)}\")\n",
    "print(f\"After elimination: {len(gdf_eliminated)}\")\n",
    "print(f\"Final polygons: {len(gdf_simplified)}\")\n",
    "print(f\"Total area: {gdf_simplified.shape_area.sum() / 10000:.1f} hectares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "1. **Scale up**: Increase test window size or process full state\n",
    "2. **Validate**: Compare with existing CSB output\n",
    "3. **Add attributes**: Run prep stage for admin boundaries and crop majority\n",
    "4. **Try experimental**: Run notebook 03 for improved segmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
